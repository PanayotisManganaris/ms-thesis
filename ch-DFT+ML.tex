\chapter{MODELS OF PEROVSKITE BAND GAP}
\label{sec:orgbfd2f81}
Novel halide perovskites with improved stability and optoelectronic properties can be designed via composition engineering at cation and/or anion sites.
Data-driven methods, especially involving high-throughput first principles computations and subsequent ML modeling using unique material descriptors, are key to achieving this goal.
I used a dataset consisting of -- among other characteristic properties -- simulated band gaps of a representative sample of halide perovskites (HaP).
The effects of mixing at different sites is described by the explicit fraction of a site occupied by a specific atomic or molecular species.
Also, a set of abstract features obtained as the weighted averages of these species' bulk physical properties is used to bolster the feature space.

The fidelity hierarchy in our data sample climbs from DFT simulations performed using the basic PBE GGA functional, to results obtained from physical experiments aggregated in literature.
\autocite{almora-2020-devic-perfor,kim-2014-cdses-nanow,swanson-2017-co-sublim}
Low fidelity data makes up the majority of the sample and serves as the foundation for interpolation.
However, it does not accuracy reproduce the experimental measurements.
My work leverages the data covered in chapters 1 and 2 to predict the band gap of arbitrary perovskite compositions at experimental actuary with little anticipated error.

To do this, a set of interpretable descriptors of each perovskite are used.
This takes the form of a 14-dimensional vector containing the atomic fractions of each of the 14 constituent species within the specified perovskite formula.
This vector is a sufficient descriptor of a perovskite and has served decent predictions.
\autocite{mannodi-kanakkithodi-2022-data-driven}
To improve regression I examine an addition 36 additional predictors derived from linear combinations of compositions and elemental properties obtained from the trusted Mendeleev databases.
\autocite{mentel-2014}

\section{Model Optimization}
\label{sec:org8f9180a}
The rigorous hyper-parameter Optimization (HPO) of any feature engineering and modeling pipeline is a problem discussed extensively in the literature.
HPO approaches can be broadly separated into exhaustive and efficient optimization strategies.
\autocite{yang-2020-hyper-optim}
We use a two-stage procedure for selecting the best model parameters.
The first stage is an exhaustive grid-search over diversely sampled parameter space.
Each combination of parameters instantiates a model which is then fit to each of a set of stratified training subsets generated by a K=3 K-fold split cross-validation strategy.
Every fitted model is subsequently cross-validated using a suite of regression scoring metrics applied to each LoT subset simultaneously using a custom SciKit-learn score adapter\footnote{\url{https://github.com/PanayotisManganaris/yogi}\label{org39fba7e}}.
The grid search is then narrowed to a high performance quadrant of the search space by the model evaluator based on recommendations made by a simple entropy minimization algorithm\textsuperscript{\ref{org39fba7e}}.
The recommended grid quickly eliminates under-performing settings based on the sample probability of a setting appearing in a set of finalists according to the scoring rankings.
The selection score is additionally influenced by a weighted sum of the scoring ranks allowing for considerable tuning of the selection criterion.
For best results, a few different grid spaces were explored to corroborate eliminations.
After the recommendation is made, the granularity of the grid is increased in the remaining ambiguous parameters and the process is repeated.
In general, no more than 2 or 3 exhaustive searches are needed over a given set of grids.
Past this point, continuously variable hyper parameters can be individually optimized by plotting validation curves.

\section{Featurization of Chemistries}
\label{sec:orgd1d9e75}
For \(\alpha\) total A-site constituents represented in the whole database, \(\beta\) total B-site constituents, and \(\gamma\) total X-site constituents, we provide a Python tool\footnote{\url{https://github.com/PanayotisManganaris/cmcl}\label{orge54c147}} which robustly coverts the composition string of each data point into a \(\alpha + \beta + \gamma\) dimensional composition vector.
In the case of our total dataset description \(\alpha + \beta + \gamma = 14\).
\autocite{yang-2022-high-throug}
In a subset of the data, the chemical vector (listing \ref{lst:cdf}) is produced using cmcl (listing \ref{lst:cmcl}).

\begin{ZZlisting}
  \caption{\label{lst:cmcl} An example of the cmcl "ft" feature accessor}
  \begin{CenteredBox}
    \begin{lstlisting}[language=python]
import cmcl
Y = load_codomain_subset()
df = Y.Formula.to_frame().ft.comp()
df.index = Y.Formula
print(df)
    \end{lstlisting}
  \end{CenteredBox}
\end{ZZlisting}

\begin{ZZlisting}
  \caption{\label{lst:cdf} Data frame of composition vectors generated by cmcl}
  \begin{CenteredBox}
    \begin{lstlisting}
                    FA   Pb   Sn    I   MA   Br
Formula                                        
FAPb_0.7Sn_0.3I_3  1.0  0.7  0.3  3.0  NaN  NaN
MAPb(I0.9Br0.1)3   NaN  1.0  NaN  2.7  1.0  0.3
    \end{lstlisting}
  \end{CenteredBox}
\end{ZZlisting}

This is naturally a sparse, relatively high dimensional descriptor.
With any growth in the composition space it becomes sparser.
This descriptor has been shown to be effective for interpolating the properties of irregularly mixed large supercells.
\autocite{mannodi-kanakkithodi-2022-data-driven}
However, a spare descriptor is generally bad for extrapolative modeling.
\autocite{ghiringhelli-2015-big-data} 

When extrapolation is the aim, continuously distributed, unique, and linearly independent features are much more reliable.
\autocite{lux-2020-inter-spars} 

Our attempts to provide a domain with these characteristics results in the following raw feature space.

\begin{itemize}
\item 14 sparse composition vectors extracted from chemical formula using \texttt{cmcl}\textsuperscript{\ref{orge54c147}}
\item 36 dense site-averaged property vectors computed as a linear combination of composition vectors and measured elemental properties \autocite{mentel-2014}
\item 5 categorical dimensions one-hot-encoding level of theory.
\begin{itemize}
\item this provides the categorical axis for multi-task learning
\item see table \ref{tbl:LoTs}
\end{itemize}
\end{itemize}

\section{Machine Learning Algorithms and Scoring Methodology}
\label{sec:orgf7d8230}
I trained Random Forest Regression (RFR) and Gaussian Process Regression (GPR) models to predict the band gap from the union of predictor features previously discussed.
I chose to use the implementations of each of these algorithms packaged with the SciKit-Learn v1.2 package for python.
\autocite{pedregosa-2011-scikit-learn} 
The hypothesis sets offered to the task by each of these architectures differ dramatically.
A RFR is a flexible nonlinear ensemble model consisting of decision trees, a simple algorithm that captures interactions between descriptors in the form of a comparative algorithm.
Each tree is trained on a random subsample of the training data, resulting in different algorithms.
The RFR prediction is made by following the algorithm of each tree to the target and averaging the results.
The advantage of this approach is that each tree is highly biased to the data allowing even minute outliers to be accounted for.
However, by using many of them, the variance in data can also be explained, thus reducing the variance of error.
Naturally, the RFR benefits from using as much data as possible with as many estimators as possible.

A GPR model is a principled linear model functioning very differently.
Informally, GPRs "remember" the training examples and judge unlabeled data by its similarity to that aggregate memory.
This is implemented as a kernel method leveraging some similarity function \(k(x, x')\).
It works out that This function defines a "universe" of functions with varying characteristics and, simultaneously a density of functions which can be interpreted as a Bayesian prior on function space.
Naturally, kernels require engineering to accommodate prior expectations. Additionally, they offer limited options for capturing non-differentiable stepwise functions.
Of course, the random forest offers nothing but stepwise functions thus posing as the opposite end of the two extremes.
By applying Bayes' rule with a likelihood function defined using the sampled data and solving for the posterior function distribution, a principled set of predictive functions is obtained.
Averaging these functions yields the mean prediction (identical to a Kriging model's ridge) and their variability gives principled estimates of the error at each point in the domain.
Due to this, the algorithm saturates after sufficient training and additional data ceases to benefit.
The primary advantage of this method is simply that it works for any two quantifiably similar \(x\), potentially vectors, text, or graphs.
This offers some possibilities for future research with enhanced features.
However this comes at the cost of \(\mathcal{O}(N^3)\) training time complexity and a break down in efficacy in sparse, high-dimensional spaces.

In order to monitor the performance of the regression during training nine metrics were used simultaneously to evaluate performance with respect to each fidelity and in the overall with attention to overall accuracy and maximum inaccuracy.
These scores were used throughout the hyper-parameter optimization to judge which parameters resulted in the best validation performance.
To train models to be more faithful to the highest fidelity, the score for that subset was weighted as more important.
So, eventually, only models that performed uniformly well on all alloy types and better on predicting the experimental dataset were selected.
From the various approaches tried, the best optimized model was selected to make experimental-quality predictions on all 37785 points in the sample space.
This procedure in demonstrated in an online notebook by \textcite{manganaris-2022-mrs-comput} hosted on the Purdue nanoHUB.

\section{Feature Engineering}
\label{sec:orgeb8814f}
There has been success in creating analytical expressions for perovskite properties, particularly lattice parameters.
\autocite{jiang-2006-predic-lattic}
In an attempt to find an analytical predictor for band gap we employ the Sure Independence Screening and Sparsifying Operator (SISSO).
\autocite{ouyang-2018-sisso} 
SISSO is a generalization of "greedy pursuit" algorithms previously used for this purpose, namely orthogonal matching pursuit (OMP) and the Least Absolute Shrinkage and Selection Operator (LASSO) otherwise known as basis pursuit.
\autocite{tibshirani-1996-regres-shrin}
The SIS\footnote{\url{https://github.com/rouyang2017/SISSO}} operator is a powerful application of compressed sensing and used to find a conceptually orthogonal basis of compound features that best explain the signal in some function.
\autocite{ghiringhelli-2017-learn-physic}
The SO is a potent dimensionality reduction, it does not perform any mathematical decomposition but instead picks existent dimensions that begin to approximate an orthogonal basis set.
It outperforms CUR decomposition by functioning effectively in extremely high rank vector spaces.
\autocite{ray-2021-various-dimen,hamm-2019-cur-decom}
This is accomplished by posing the decomposition as a compressed sensing problem in the correlation metric space.
Together, these operators allows the program to effectively find candidates for a linearly independent basis in a vector space of immense size.
Unlike legacy techniques it does not suffer when features are correlated.
\autocite{tibshirani-1996-regres-shrin,gauraha-2018-introd-to-lasso}
This high performance handling of highly correlated vectors makes it particularly appealing for use with the perovskite features.
The features illustrated in figures \ref{fig:pprop} are derived from those in figure \ref{fig:pcomp}.
Those composition vectors, due to the fact that they represent a unit formula are themselves correlated.
At the least, they trace a bounded space.

A full SISSO model produces a parsimonious model of the target property which is easy to interpret.
Subsequent applications of the SISSO operator to the residuals of the previous model serve as a clever interrogation of error\autocite{mayo-1998-error-growt} yielding additional terms that, at the cost of simplicity, better explain the target.
Notice, however, the large space of features contains more good explanatory features than are used in the final expression.
I extensively modified a SciKit-learn compliant \autocite{buitinck-2013-api} interface\footnote{\url{https://github.com/PanayotisManganaris/pysisso}} to the SISSO program originally developed by Matgenix\footnote{\url{https://github.com/Matgenix/pysisso}} for the purpose of better leveraging these cut explanatory features.
The goal of this approach was to overcome the limitations of the raw feature space by finding a basis of varied, unique, and descriptive features which could serve as the domains for more powerful estimators.
I planned to use this strategy to train SIS-augmented versions of the RFR and GPR models previously discussed.
I additionally hoped that this could help to cut down the total number of descriptors necessary, especially the sparse features.
To improve the interpretability of these, the SIS algorithm was restricted to combining raw features in ways that preserved their units, so to preserve overall interpretability.
SIS features complexity was restricted to a maximum of 3 operations primarily to encourage parsimonious descriptions.
The operations in table \ref{tbl:ops} were used to create compound features.

\begin{table}[htbp]
\caption{\label{tbl:ops} Operations for formation of combinatorial super-space}
\centering
\begin{tabular}{ll}
Binary & Unary\\[0pt]
\hline
addition & reciprocation\\[0pt]
subtraction & power 2\\[0pt]
multiplication & power 3\\[0pt]
division & natural logarithm\\[0pt]
 & exponentiation\\[0pt]
 & root 2\\[0pt]
\end{tabular}
\end{table}

\section{Training and Evaluation Methodology}
\label{sec:org3f842dd}
First, the sample set is shuffled to mitigate the models tendency to fit on sampling order.
Model training proceeded only after partitioning the dataset using an 80/20 train-test split.
The split was made in a stratified manner, ensuring both partitions contained a proportionate fraction of samples from each fidelity subset.
The test set of 282 points was held out for final evaluation.
The training used the remaining 1123 data points.
In order to specify the learning algorithm best at predicting the experimental fidelity from simulated data, a thorough grid-search of each algorithm's hyper-parameters was performed.
First an estimator pipeline was constructed as in figure \ref{fig:pipe}.
Any sparse vectors were made dense and NaNs were filled with zeros by a \texttt{SimpleImputer}.
The feature vectors were subject to l1 normalization so that the compound's stoichiometry converted to ratios.
The estimator at the end of the pipeline was instantiated with default parameters and later had optimal settings injected.

To find these settings, I opted for a \(K\)-folds validation strategy first necessitating an optimal value for \(K\) be found.
This was done empirically, first by generating learning curves with \(K=10\) for each estimator.
The knee on these plots indicates the minimum number of samples needed to train effectively on average.
The size of one fold would be the size of the validation set, with the remaining folds used in training.
So, I doubled the number of samples at the knee, subtracted it from the size of the total training partition and used the result to determine the size of one fold.
This method resulted in setting \(K = 3\) for GPR training and \(K = 4\) for RFR training.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{MACHINE_LEARNING_MODELS_OF_PEROVSKITE_BAND_GAP/2023-06-05_14-20-21_screenshot.png}
\caption{\label{fig:pipe} SciKit-Learn pipeline terminating in a default random forest estimator}
\end{figure}

Finally I performed hyper-parameter optimization by exhaustive grid search using methods discussed in section \ref{sec:org8f9180a}.
Optimizing a model this way was expected to result in a good ability to interpolate perovskites properties in the well covered sample space detailed in figure \ref{fig:coverage}.
Ideally, the resulting model need only extrapolate over the one-hot-encoded LoT dimensions.
To confirm this, validation requires two approaches.

In order, the first approach was critical to confirm the model was capable of predicting properties of entirely unseen compositions.
A modified method of leave-one-out cross-validation was used to understand the distribution of possible errors.
The optimally parametrized model was retrained on a dataset derived from the train set where one particular combination of elements is not present at all in any stoichiometry and tasked to make predictions on a validation set of the excluded compounds.
To be clear, individual elements may be represented in the training set as long as they don't appear together in a single compound.
This strategy better tested the model's ability to comprehend novel compounds which it saw many of in the total sample space.
Additionally, this avoided the expense of true leave-one-out validation.
The second validation was to test that the model can accurately predict the values for specific unseen elements at different levels of theory.
In this case, test compounds need not be entirely unique because it was expected that the extrapolated predictions at higher levels of theory will leverage the better coverage of lower fidelity sample sets.
So, finally, the test set is used and the resulting predictions are evaluated for accuracy.
Shapley Additive Explaination (SHAP) analysis of the models lends insight to the average physical impacts of 1) site-specific alloying, 2) using organic molecules in the Perovskite superstructure, and 3) the distribution of effects that a level of theory has on the prediction.

\section{Results}
\label{sec:orgfa003dc}
\subsection{Best Models on Raw Domain}
\label{sec:orgf476608}
 
\begin{figure}[htbp]
\centering
\includesvg[width=450pt]{./.ob-jupyter/1a3fd80c6a22dbce291d740dbb832e523b9d11eb}
\caption{\label{fig:pairplots} model predictions vs true values at multiple fidelities}
\end{figure}

Following HPO these models are finally validated against the test sets originally split off from the sample for both their extrapolative ability and consistency.
The random forest model was the best performing compared to the Gaussian process and SISSO regressions.
The analysis of its ability to make extrapolative predictions on completely unknown compositions is discussed in the following section \ref{sec:orgb2d5fd7}.
The RFR boasts an RMSE error on the total dataset of only 0.12 \unit{\electronvolt}.
This combined with its RMSE error of 0.15 \unit{\electronvolt} on the experimental fidelity subset promises this model can make quality predictions of the band gap at the experimental fidelity.
See table \ref{tbl:LoTscores}.
This error compares favorably with the best models currently ranked by the Materials Project's MatBench standard.
\autocite{dunn-2020-bench-mater}
Notably, these models use only the stoichiometry of the compositions while most MatBench models require atomic structures in addition to stoichiometric information.
Of course, these models are highly specialized to this sample space.
The RFR hyper-parameters are listed in the appendix (Table \ref{tbl:rfrHPO}).

The GPR model was tried with various kernels, both stationary and non-stationary, where each essentially describe the differentiability of the functions used in the posterior.
Ultimately, the best was a non-stationary Matern kernel with \(\nu = \frac{3}{2}\).
This kernel defines "rough" functions that are only once-differentiable.
This makes sense considering the inability of GPR to capture step functions and the stepwise nature of the LoT encoding dimensions.
Additionally, both the LoT dimensions and the composition vectors are sparse, which challenges the algorithm
Nevertheless, it is a close second to the RFR and offers a propitious start to models utilizing more advanced features.

\subsection{SISSO Model and SIS Engineered Features}
\label{sec:org3c8eaf2}
The Sure Independence Screening and Sparsifying Operator (SISSO) is a specific combination of multiple data mining techniques chained together resulting in a symbolically expressed regression model.
\autocite{ouyang-2018-sisso,ghiringhelli-2017-learn-physic} 

The best SISSO model for band gap involving 3 SIS features (each composed of up to 4 basic features) has an unremarkable RMSE of 0.476 eV, barely outperforming an OLS regression on 55 dimensions (see Table \ref{tbl:LoTscores}).
It is expressed in equation \ref{eq:bgexp}.
Notably, while the units of the expression do not match the units of band gap as measured (target units are unknown to the algorithm), they are still energy units.
This is by design, as the combination of features was restricted so to only allow compatible units to be combined.
A separate training session without this restriction was attempted, but the resulting model's performance was worse.

\begin{align}
\label{eq:bgexp}
bg\,\si{\electronvolt} = 1.752393064 &((X;\mbox{electronegativity}*A;\mbox{heat of fusion})-\nonumber\\&(B;\mbox{electron affinity}+B;\mbox{ionization energy}))\nonumber\\+-0.5862929089 &((B;Sn-\mbox{HSE})+(\mbox{PBE}-X;\mbox{electronegativity}))\nonumber\\+1.063684923 &((A;\mbox{electronegativity}-B;Ca)*(B;\mbox{heat of vap}-X;\mbox{electron affinity}))\nonumber\\+4.657097107
\end{align}

\begin{table}[htbp]
\caption{\label{tbl:LoTscores} RMSE of models on raw domain calculated per LoT subset}
\centering
\begin{tabular}{lrrrrrr}
rmse scores & GPR & RFR & Linear OLS & SISSO & SIS + GPR & SIS + RFR\\[0pt]
\hline
total & 0.15 & 0.12 & 0.49 & 0.47 & 0.25 & 0.18\\[0pt]
EXP & 0.12 & 0.15 & 0.30 & 0.33 & 0.33 & 0.23\\[0pt]
PBE & 0.12 & 0.10 & 0.47 & 0.39 & 0.17 & 0.13\\[0pt]
HSE & 0.21 & 0.15 & 0.55 & 0.51 & 0.30 & 0.20\\[0pt]
HSE(SOC) & 0.15 & 0.10 & 0.53 & 0.57 & 0.27 & 0.22\\[0pt]
HSE-PBE(SOC) & 0.13 & 0.13 & 0.46 & 0.47 & 0.25 & 0.18\\[0pt]
\end{tabular}
\end{table}

Computing and combining more than 3 SIS features is not rewarding of the computational expense.
Residuals are increasingly uncorrelated with the generated SIS features and model accuracy gains do not outstrip complexity.
However, in the process of creating Equation \ref{eq:bgexp}, 150 SIS predictor variables were determined and recorded.
50 primary predictors, 50 first residual predictors, and 50 second residual predictors.
These can serve as a high quality, introspective domain for the other architectures to fit on.

\subsection{Best Models on Engineered Domain}
\label{sec:org7802582}
We set the aim of decreasing \(\mathcal{O}(n^3)\) computational expense of GPR by \(\approx\)10 times.
So, we aim to take 30 highly correlated features (slightly more than one half the number used by prior models) from these SIS subspaces.
We expected this to solve the problems inherent to the raw \ref{sec:orgd1d9e75}.

Fitting models to SIS features may leverage the denser and more continuous domain to improve extrapolative predictions.
Potentially into the high-entropy domain, or simply Theory.
However using the SIS subspaces in this way compromises on SISSO's explicability and necessitates SHAP analysis.
Unfortunately, whatever the gains in training time complexity and extrapolative ability, the models underperformed in predicting band gap in the cardinal mixing domain (see Table \ref{tbl:LoTscores}).
This was unexpected considering the raw features are by their nature highly correlated and presumed redundant.
Nevertheless, the RFR model on the higher dimensional, sparser raw features is superior.

 
\begin{figure}[htbp]
\centering
\includesvg[width=450pt]{./.ob-jupyter/383e3b86e9b2d36279558672c6ca56306fae9032}
\caption{\label{fig:sis-pairplots} SIS-based model predictions vs true values at multiple fidelities}
\end{figure}

\section{Discussion}
\label{sec:orgb2d5fd7}
\subsection{Validation of Expected Error}
\label{sec:orgee265d6}
The errors reported in the prior section are promising but questionable due to the lack of testing of the model's ability to make predictions on completely novel compounds.
Following the appropriate validation methodology outlined in section \ref{sec:org3f842dd} addresses this concern.
This results in a distribution of errors with a mean EXP RMSE of about 0.2 \unit{\electronvolt}, which is only slightly worse than error obtained in the testing.
The mean scores are better than the median, but this is mostly due to a small number of outlier compounds which are not very exotic, so it is unrealistic not to train on at least one example of them at a simulation fidelity.
See figure \ref{fig:errval}.
There is definitely a loss in validation performance as compared to the scores on the train set, see table \ref{tbl:errval}.
Notice, the \(R^2\) score is missing because it can not be computed on validation sets that contain only a single sample.
The explained variance (ev) score is poor on the test set, but nearly perfect on the train set.
This is the biggest difference in the scoring by far, simply due to the higher variability of errors in the test sets.
Certainly, the interpolation demanded of the model will not be perfect on wholly unseen compositions, but it seems that in the majority of instances, the prediction can be justifiably expected to be reasonably accurate.

 
\begin{figure}[htbp]
\centering
\includesvg[width=1000pt]{./.ob-jupyter/d44a36fb406250843e09ef8033a779d1b729d413}
\caption{\label{fig:errval} Distribution of leave-one-composition-out cross-validation errors weighted by the size of validation sets}
\end{figure}

 
\begin{table}[htbp]
\caption{\label{tbl:errval} Leave-one-composition-out cross-validation scored by complete suite}
\centering
\begin{tabular}{lrr}
partition & test & train\\[0pt]
\hline
ev & -2.48 & 0.99\\[0pt]
maxerr & 0.32 & 0.96\\[0pt]
rmse & 0.22 & 0.10\\[0pt]
rmse\textsubscript{EXP} & 0.22 & 0.06\\[0pt]
rmse\textsubscript{PBE} & 0.18 & 0.11\\[0pt]
rmse\textsubscript{HSE} & 0.22 & 0.11\\[0pt]
rmse\textsubscript{HSE}(SOC) & 0.21 & 0.10\\[0pt]
rmse\textsubscript{HSE}-PBErel(SOC) & 0.20 & 0.10\\[0pt]
\end{tabular}
\end{table}

\subsection{SHAP Analysis of Domain}
\label{sec:org0359b0f}
SHAP scores are computed automatically for every dimension of every sample in the domain by the python SHAP package\footnote{\url{https://github.com/slundberg/shap}}.
The sum of the expectation value of the target conditioned on the model features and the  SHAP scores computed for each predictor variable of a sample is the model's  prediction for that sample target.
\autocite{lundberg-2017-unified-approac}
For the perovskite band gap the expectation value is 2.836 when conditioned on the raw features and 2.863 when conditioned on the SIS features.
The raw features' SHAP values are more centered around zero while engineered features are more often scored decisively positive or negative.

Figures \ref{fig:rfrSHAP} and \ref{fig:gprSHAP} show the top score distributions.
In each figure, features are ranked by overall value on the y-axis.
The x-axis shows the SHAP score for each point.
The points are shaped in a violin plot to show the distribution of effects the presence of the given feature can have.
Finally, on the color-axis, feature value specifies whether a particular score is a large or small absolute contributor of the sum to the prediction.

For instance, in figure \ref{fig:rfrSHAP}, the B-site Electronegativity is often a strongly positive contributor to the RFR prediction.
However, almost always in this case it is out-contributed by other features, it does not mostly determine the result but it is still valuable.
On the contrary, when it is a strongly negative contributor it effectively determines the result.
It is interesting to see how models make use of features in light of basic bi-variate correlations.
The only features that correlate strongly with band gap are illustrated in figure \ref{fig:rpear}.
Notably, the Random Forest Regression (RFR) primarily uses the highly correlated features, while the Gaussian Process Regression (GPR) primarily uses features with lower Pearson correlations.

\begin{figure}[htbp]
\centering
\includegraphics[width=450pt]{/home/panos/Documents/manuscripts/DFT+ML+feature_engineering/RFR/.ob-jupyter/27cc6a3fc4eab6935fcc0988ea4ac382c4eb8147.png}
\caption{\label{fig:rfrSHAP} Random Forest Regression Band Gap SHAP Values}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=450pt]{/home/panos/Documents/manuscripts/DFT+ML+feature_engineering/GPR/.ob-jupyter/31552cf23170d5409f0d7f373221bd1784e2b209.png}
\caption{\label{fig:gprSHAP} Gaussian Process Regression Band Gap SHAP Values}
\end{figure}

 
\begin{figure}[htbp]
\centering
\includesvg[inkscapeformat=png, inkscapedpi=300,width=400pt]{./.ob-jupyter/f93593f90e4b5b8cccd7c1395b6e9977e884e8d9}
\caption{\label{fig:rpear} raw features with (\(|p| > 0.5\)) against band gap}
\end{figure}

SHAP scores in principle quantify the contributions of site members and site member properties to the perovskite band gap.
On a sample-by-sample basis it is possible to say how much of the bandgap is contributed by the presense of a given quantity of, for example, Germanium.
However a clustering analysis reveals no universal patterns.
SHAP scores given the raw domain are near zero on average regardless of partitions made by level of theory, alloy scheme, or presence of organic A-site occupants.
This analysis confirms the difficulty of deducing a rule of thumb for the synthesis of perovskites with desirable properties.
If anything, figure \ref{fig:clusters} confirms that the Iodine at the X site tends to slightly increase band gaps.

 
\begin{figure}[htbp]
\centering
\includesvg[width=450pt]{./.ob-jupyter/df6e096d29860b55fe5610a23627968785eebc23}
\caption{\label{fig:clusters} SHAP score distributions reveal effects of individual constituents}
\end{figure}

\subsection{Predictions and Screening}
\label{sec:org37dcca4}
Using the superior RFR model, I predict the band gap for all 37785 possible compositions demonstrating cardinal mixing within the bounds of a 2x2x2 perovskite super cell.
That is eight A-sites shared by up to 5 constituents, 8 B-sites shared by up to six constituents, and 24 X-sites shared by up to 3 constituents.
Given the good coverage achieved by our sample dataset (figure \ref{fig:coverage}) and according to the scores reported in Table \ref{tbl:LoTscores}, the RFR model is capable of predicting band gaps at the experimental fidelity with a 0.15 RMSE.
These predictions were projected on the sample space in Figure \ref{fig:pred}.

 
\begin{figure}[htbp]
\centering
\includesvg[width=450pt]{./.ob-jupyter/2a6257e7d00092bdcc8f561301ee50cdbb7b8975}
\caption{\label{fig:pred} Band gap predictions overlaid on cardinal mixing chemical domain projected from fourteen to two dimensions via t-SNE}
\end{figure}

I followed a similar high-throughput screening procedure to that laid out in prior works, except this covered a large space of purely hypothetical compounds.
\autocite{yang-2023-high-throug,mannodi-kanakkithodi-2021-comput-data}
See figure \ref{fig:screenops}.
Band gaps between 1 and 2 \unit{\electronvolt} were selected as this range is expected to yield the best power conversion efficiency (PCE) in the visible spectrum.
\autocite{yu-2012-ident-poten,shockley-1961-detail-balan}
Perovskite compounds were selected for their predicted stability by cutting on each of three tolerance factors previously established in chapter 1.
The constituent ratios of the chosen compositions in figure \ref{fig:chosenstats} may be juxtaposed with figure \ref{fig:domainstats}.

\begin{figure}[htbp]
\centering
\includegraphics[width=250pt]{screening_ops.png}
\caption{\label{fig:screenops} Summary of screening operations used to identify candidate compounds}
\end{figure}

 
\begin{figure}[htbp]
\centering
\includesvg[inkscapeformat=png, inkscapedpi=300,width=300pt]{./.ob-jupyter/aa9e831e252cb3559416e458c47f5cce2ca96a82}
\caption{\label{fig:chosenstats} The compounds selected from the cardinal mixing sample space contain varying fractions of each element}
\end{figure}

These cuts trimmed the 37785 points by 97\% to a subset of only 1251 viable candidates.
These selected candidates were projected onto the t-SNE embedding space in Figure \ref{fig:chosen}.
A Frequency analysis revealed the constituent elements of the chosen subset most often occupied either small or large shares of their site.
Most A-site constituents preferred occupying 1/8\textsuperscript{th} of their site at a rate of about 8\%, with Potassium and Rb also preferring full occupancy 10-12\% of the time.
B-site constituents favored pure configurations at a rate of 5-8\% but also showed some preference for doping configurations.
X-site constituents, however showed very strong preference for fully occupying their site 25\% of the time.
See figure \ref{fig:freq}.
The strong preference for pure sites simply reflects that this sample space contained compositions mixed at no more than one site simultaneously.

 
\begin{figure}[htbp]
\centering
\includesvg[width=450pt]{./.ob-jupyter/09b87051881c9559cbbc102bf3a024c6ebea0f57}
\caption{\label{fig:freq} Frequency of mixing fractions of species at the A, B, and X sites across the \textasciitilde{}1200 screen compounds}
\end{figure}

\chapter{CONCLUSIONS}
\label{sec:org1da08e8}
A set of promising hypothetical compositions is identified by this work.
I identified a set of 1251 promising perovskite compositions with desirable band gaps for Photovoltaic applications using a novel data-driven approach.
Of the selected compositions 640 are purely inorganic, and 611 are hybrid-organic/inorganic.
Table \ref{tbl:mixscreen} shows how the set subdivides by mixing.
Only 40 of the original expertly designed sample pass the screening, the rest are untested to my knowledge.
This shows that there is still much opportunity for discovery in this area and much to be learned about this chemistry.
Notably, 834 contain no lead.
The 30 most stable lead-free compounds identified with band-gap in the 1-2 \unit{\electronvolt} range are listed in table \ref{tbl:pbfree}.

I evaluated a variety of machine learning techniques and implemented simple but effective models for estimating band gap for perovskites from multi-fidelity data.
On held-out test data, a random forest model achieved nearly an RMSE error of 0.12 on the whole dataset and 0.15 on the experimental subset.

I found RFR models performed best in this setting, and believe this is because the architecture is an ensemble model so it reduces the variance of error by design.
Additionally, the decision trees that make up the forest best identify and capture relevant feature interactions as corroborated by Pearson correlations.
Trees also flexibly represent complex nonlinear relationships between feature interactions and band gap.
RFR models may be data hungry but are generally better about accommodating outliers.
The RFR properties that helped it perform best in this setting are not domain-specific and therefore are likely to apply to other material properties and for other types of compounds.

In summary, I experimented with training multiple models to differentiate and treat appropriately observations with different fidelities and demonstrated good results with the RFR in particular.
The Gaussian Process Regression was a very close second.
The GPRâ€™s ability to theoretically deal with more complex descriptors deserves further study to realize its full potential.
Further improving on the feature engineering and examining what can be learned about the relationship between structure and band gap might begin here.

 
\begin{table}[htbp]
\caption{\label{tbl:mixscreen} Number of selected data points with given mixing site}
\centering
\begin{tabular}{lr}
 & count\\[0pt]
\hline
A & 605\\[0pt]
B & 388\\[0pt]
X & 256\\[0pt]
pure & 2\\[0pt]
\end{tabular}
\end{table}

 
\begin{table}[htbp]
\caption{\label{tbl:pbfree} Thirty hypothetical lead-free formulae and their predicted band gaps}
\centering
\begin{tabular}{rlr}
 & Formula & band gap [eV]\\[0pt]
\hline
19290 & FA0.375Rb0.625Sn1.000I1.000 & 1.98\\[0pt]
19309 & FA0.375MA0.125Rb0.500Sn1.000Cl1.000 & 1.99\\[0pt]
19310 & FA0.375MA0.125Rb0.500Sn1.000Br1.000 & 1.95\\[0pt]
19306 & FA0.375MA0.125Rb0.500Sr1.000Cl1.000 & 1.95\\[0pt]
19308 & FA0.375MA0.125Rb0.500Sn1.000I1.000 & 1.70\\[0pt]
19307 & FA0.375MA0.125Rb0.500Sr1.000Br1.000 & 1.96\\[0pt]
19304 & FA0.375Rb0.625Ba1.000Br1.000 & 1.93\\[0pt]
19303 & FA0.375Rb0.625Ba1.000Cl1.000 & 1.89\\[0pt]
19305 & FA0.375MA0.125Rb0.500Sr1.000I1.000 & 1.74\\[0pt]
19302 & FA0.375Rb0.625Ba1.000I1.000 & 1.68\\[0pt]
19076 & FA0.250K0.250MA0.375Rb0.125Sn1.000Br1.000 & 1.93\\[0pt]
19301 & FA0.375Rb0.625Ca1.000Br1.000 & 1.69\\[0pt]
19300 & FA0.375Rb0.625Ca1.000Cl1.000 & 1.72\\[0pt]
19324 & FA0.375MA0.250Rb0.375Sr1.000Cl1.000 & 1.72\\[0pt]
19008 & FA0.250K0.125MA0.625Ge1.000I1.000 & 1.93\\[0pt]
19056 & FA0.250K0.250MA0.250Rb0.250Sn1.000I1.000 & 1.84\\[0pt]
19004 & FA0.250K0.125MA0.625Sn1.000Br1.000 & 1.77\\[0pt]
19032 & FA0.250K0.250Rb0.500Ba1.000I1.000 & 1.95\\[0pt]
19073 & FA0.250K0.250MA0.375Rb0.125Sr1.000Br1.000 & 1.94\\[0pt]
19094 & FA0.250K0.250MA0.500Sn1.000Br1.000 & 1.87\\[0pt]
19049 & FA0.250K0.250MA0.125Rb0.375Ca1.000Br1.000 & 1.85\\[0pt]
19003 & FA0.250K0.125MA0.625Sn1.000Cl1.000 & 1.75\\[0pt]
19074 & FA0.250K0.250MA0.375Rb0.125Sn1.000I1.000 & 1.68\\[0pt]
19002 & FA0.250K0.125MA0.625Sn1.000I1.000 & 1.46\\[0pt]
19053 & FA0.250K0.250MA0.250Rb0.250Sr1.000I1.000 & 1.88\\[0pt]
19075 & FA0.250K0.250MA0.375Rb0.125Sn1.000Cl1.000 & 1.95\\[0pt]
19070 & FA0.250K0.250MA0.250Rb0.250Ba1.000Br1.000 & 1.86\\[0pt]
19093 & FA0.250K0.250MA0.500Sn1.000Cl1.000 & 1.86\\[0pt]
19001 & FA0.250K0.125MA0.625Sr1.000Br1.000 & 1.71\\[0pt]
19091 & FA0.250K0.250MA0.500Sr1.000Br1.000 & 1.89\\[0pt]
\end{tabular}
\end{table}
